---
params:
   new_title: "My Title!"
title: "`r params$new_title`"
author: "Kristina Øie Kvile, NIVA"
date: '`r format(Sys.Date(), "%d %B %Y")`'
output: 
  html_document:
    toc: true # Gir Table of Contents i starten av dokumentet
    toc_depth: 2
# Lagrer til html, kommenter ut dette når scriptet kjøres i løkke fra analyses_neqr.R:
# knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), 'Full_summaries/H_new.html')) })
editor_options: 
  chunk_output_type: console
---

```{r settings, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE) # Fjerner beskjeder fra R i output

# libraries
library(readxl)
library(tidyverse)
library(stringi)
library(sf) # For kart
library(gridExtra) # For kart
library(cowplot) # For kart
library(RColorBrewer)
library(magrittr)
library(knitr)
sourceDir <- function(path, trace = TRUE, ...) {
  for (nm in list.files(path, pattern = "[.][RrSsQq]$")) {
    if(trace) cat(nm,":")
    source(file.path(path, nm), ...)
    if(trace) cat("\n")
  }
}
sourceDir('R')

options(dplyr.width = Inf) # Viser alle kolonner i table
options(dplyr.print_max = 1e9)

print_kable = function(x) {
  print(kable_print_output <<- x)
  cat('\n')
}
```

Dette dokumentet går gjennom arbeidsflyten i R for å kjøre statistiske analyser og predikere NEQR-verdier for alle kommuner og ønskede år, for de indikatorene NIVA skal levere til Naturindeksen. De predikserte NEQR-verdiene blir lastet opp til NI-databasen ved hjelp av biblioteket NICalc i scriptet <a href="https://github.com/NIVANorge/naturindeks/blob/main/analyser/NICalc_upload.r" title="NICalc_upload">NICalc_upload</a>. Dette R markdown-dokumentet kan kjøres i løkke for flere variabler i scriptet <a href="https://github.com/NIVANorge/naturindeks/blob/main/analyser/analyses_neqr.r" title="NICalc_upload">analyses_neqr</a>.  

# Databehandling

Først laster vi inn data for en indikatoren som skal analyseres, konvertert fra rådata til nEQR-verdier i scriptet <a href="C:/Users/KVI/NIVA/240176 - Naturindeks for Norge 2025 - Documents/03_Data_and_analyses/naturindeks/analyser/convert2neqr.r" download>convert2neqr.r</a>. Vi laster også inn datasett med oversikt over alle kommuner, vannforekomster, økoregioner og vanntyper, for det relevante habitatet til den gitte indikatoren. 

```{r load_data, echo=FALSE}
# Definererer alle NI-indikatorene:
ind_names <- array(c("Naturindeks plankton innsjøer",
                 "Begroing eutrofierings indeks elver",
                 "Begroing elver forsurings indeks",
                 "Vannplanter innsjøer",
                 "Hardbunn vegetasjon algeindeks kyst",
                 "Hardbunn vegetasjon nedre voksegrense kyst",
                 "Bløtbunn artsmangfold fauna kyst",
                 "Bløtbunn eutrofiindeks kyst",
#                 "Blåskjell",
                 "Planteplankton kyst"),dim=c(1,9),
#dimnames = list(1,c("PTI","PIT","AIP","TIc","RSLA","MSMDI","H","NQI1","blaaskjell","Chla")))
dimnames = list(1,c("PTI","PIT","AIP","TIc","RSLA","MSMDI","H","NQI1","Chla")))

#index <- "PIT" # Definererer hvilken indikator vi skal analysere. Kommenter ut når scriptet kjøres i løkke fra analyses_neqr.R
print(paste0("Indikator: ",ind_names[,index]," (",index,")"))

# Laster inn fil med NEQR-verdier:
ForcingData_name <- paste0("../../01_Data/03_NEQR/NEQR_",index,".xlsx")
print(paste0("Fil med nEQR-verdier (ForcingData): ",ForcingData_name))
ForcingData  <- read_xlsx(ForcingData_name) %>% 
  mutate(Year = as.numeric(Year)) # Setter år til kontinuerlig variabel

# Definerer habitat (innsjø, elver eller kyst):
if(index %in% c("PTI","TIc")){
  habitat <- "innsjo"
}else if(index %in% c("PIT","AIP")){
  habitat <-"elver"
}else if(index %in% c("RSLA","MSMDI","NQI1","H","blaaskjell","Chla")){
  habitat <-"kyst"
}

print(paste0("Habitat: ",habitat))

# Laster inn fil med liste over alle vannforekomster vi skal predikere for
PredData_name  <- paste0("../../01_Data/02_Vannforekomster/Naturindeks-",habitat,".xlsx")
print(paste0("Fil med alle vannforekomster/kommuner (PredData): ",ForcingData_name))

print(paste0("PredData: ",PredData_name))
PredData  <- read_xlsx(PredData_name)  %>% 
  mutate(Kommunenr = as.numeric(Kommunenr)) #Setter kommunenr til numerisk

# Observasjoner per år i data:
kable(ForcingData %>% count(Year, sort = FALSE),caption = "Observasjoner per år i ForcingData:")

# Plot av fordeling i NEQR-verdier i data:
par(mfrow = c(1,1), mar = rep(2,4),oma = rep(2,4))
hist(ForcingData$Response,main=paste0("Fordeling av data for respons-variabel: ",index),xlab="",ylab="")

#print(paste0("Verdier >1 i data: ",round(100*length(ForcingData$Response[ForcingData$Response>1])/length(ForcingData$Response))," %"))
#print(paste0("Verdier = 1 i data: ",round(100*length(ForcingData$Response[ForcingData$Response==1])/length(ForcingData$Response))," %"))

rm(ForcingData_name, PredData_name)

```
  
Vi klargjør datasettet for modelleringen ved å:  
1. Splitte "vanntype" i sine delkomponenter ("typologifaktorer")   
2. Slå sammen de to nordlige økoregionene for ferskvann
  
Dette gjøres for både ForcingDataog og PredData.  

For oversikt over typologifaktorer se <a href="https://www.vannportalen.no/veiledere/klassifiseringsveileder" title="Klassifiseringsveileder 02:2018">Klassifiseringsveileder 02:2018</a>. 

```{r prepare_data, echo = FALSE}
# Definerer variablene ("typologifaktorer") som går inn i vanntype:

if(habitat == "innsjo"){
variabler<-c("Vannkategori","Okoregion","Klimaregion","Storrelse","Kalk","Humus","Turbiditet","Dybde")
} else if(habitat == "elver"){
  variabler<-c("Vannkategori","Okoregion","Klimaregion","Storrelse","Kalk","Humus","Turbiditet")
} else if(habitat == "kyst"){
  variabler <- c("Vannkategori","Okoregion","Kysttype","Salinitet","Tidevann","Bolgeeksponering",
               "Miksing_i_vannsoylen","Oppholdstid","Gjennomstromminghastighet")
}

# Løkke for å gjøre endringer i både ForcingData og PredData:
for(datname in c("ForcingData","PredData")){
  dat <- as.data.frame(get(datname)) # Henter dattasettet
  
  # Fjerne observasjoner med manglende vanntype eller vanntype satt til 0:
  dat <- 
    dat %>%
    filter(!is.na(Vanntype)) %>%
    filter(Vanntype!=0)
  
  # Splitter opp Vanntype i sine delkomponenter:
  for(i in 1:length(variabler)){
    dat[,variabler[i]] <- substr(dat$Vanntype,i,i)
  }
  
  for(i in 1:length(variabler)){
    dat[,variabler[i]] <- substr(dat$Vanntype,i,i)
  }
  
  
# Endrer koding for noen variabler:
  if(habitat == "innsjo"){
    dat<- dat %>%
      mutate_at(variabler[c(5:8)], as.numeric)  %>% 
      mutate(Kalk = na_if(Kalk,9))  %>%   #  Kalk=9 -> NA 
      mutate(Kalk = replace(Kalk,Kalk%in%c(5:8),1)) %>% #Kalk=[5-8] -> 1
      mutate(Humus = na_if(Humus,0)) %>%  # Humus=0 -> NA
      mutate(Dybde = na_if(Dybde,0)) %>%   # Dybde=0 -> NA 
      mutate(Dybde = replace(Dybde,Dybde==4,1)) %>% #Dybde=4 -> 1 (Svært grunn, estimert)
      mutate(Dybde = replace(Dybde,Dybde==5,2))  %>% #Dybde=5 -> 2   (Grunn, estimert)
      mutate(Dybde = replace(Dybde,Dybde==6,3)) #Dybde=6 -> 4   (Dyp, estimert)
    
    }

  if(habitat == "elver"){
     dat<- dat %>% 
       mutate_at(variabler[c(4:7)], as.numeric)  %>% 
       mutate(Kalk = na_if(Kalk,9))  %>%   #  Kalk=9 -> NA 
       mutate(Kalk = replace(Kalk,Kalk%in%c(5:8),1)) %>% #Kalk=[5-8] -> 1
       mutate(Humus = na_if(Humus,0)) # Humus=0 -> NA
  }
  
  if(habitat == "kyst"){ #0 = NA for flere variablre
    dat<- 
      dat %>% 
      mutate_at(variabler[c(3:9)], as.numeric)  %>% 
      mutate(Tidevann = na_if(Tidevann,0)) %>%   
      mutate(Bolgeeksponering = na_if(Bolgeeksponering,0)) %>%   
      mutate(Miksing_i_vannsoylen = na_if(Miksing_i_vannsoylen,0)) %>%    
      mutate(Oppholdstid = na_if(Oppholdstid,0)) %>%   
      mutate(Gjennomstromminghastighet = na_if(Gjennomstromminghastighet,0))   
  }
  
  # Slår sammen de to nordligste økoregionene for ferskvanns-habitat:
  if(habitat %in% c("innsjo","elver")){
    Nordnorge <- c("N", "F") 
    dat <- 
    dat %>% 
    mutate(Okoregion = ifelse(Okoregion %in% Nordnorge, "N", Okoregion)) 
    rm(Nordnorge)
  }
  
  # Gjør om variabler til faktor
  dat <-
    dat %>%
    mutate_at(variabler,as.factor) 
  
  assign(datname, dat)  # Oppdaterer det opprinnelige datasettet
  rm(dat, datname)
}

# Antall observasjoner per Okoregion:
kable(ForcingData %>% group_by(Okoregion) %>% summarise(`Ant. Vanntyper` =  length(unique(Vanntype)), `Ant. obs` = n()),
        caption = "Observasjoner per økoregion i ForcingData:")

kable(PredData %>% group_by(Okoregion) %>% summarise(`Ant. Vanntyper` =  length(unique(Vanntype)), `Ant. obs` = n()),
        caption = "Observasjoner per økoregion i PredData:")

# Observasjoner per kode (nivå) i typologifaktorer 
kable(ForcingData %>%
    gather(key = "factor", value = "level", variabler) %>%
    group_by(factor, level) %>%
    summarize(count = n()) %>%
    ungroup() %>%
    spread(key = factor, value = count, fill = 0)  %>%
    rename(Kode = level)  %>%
    dplyr::select(c(Kode, variabler)),
    caption = "Observasjoner per kode (nivå) i typologifaktorer for ForcingData:")

kable(PredData %>%
    gather(key = "factor", value = "level", variabler) %>%
    group_by(factor, level) %>%
    summarize(count = n()) %>%
    ungroup() %>%
    spread(key = factor, value = count, fill = 0)  %>%
    rename(Kode = level)  %>%
    dplyr::select(c(Kode, variabler)),
    caption = "Observasjoner per kode (nivå) i typologifaktorer for PredData:")

  
par(mfrow=c(2,5),mar=c(2,1,2,1),oma=c(1,1,3,1))
for (var in variabler)
{
  boxplot(ForcingData$Response~unlist(ForcingData[,var]),main=var,xlab="",ylab="")
}
mtext(side=3, paste0("Fordeling av ",index, " (nEQR) per kode i typologifaktorer i ForcingData"), outer = TRUE)

# Oversikt for kalk
# 1 Svært kalkfattig: Ca < 1 mg/L, Alk < 0,05 mekv/L
# 2 Kalkfattig: Ca 1-4mg/L,Alk.0,05-0,2mekv/L
# 3 Moderat kalkrik: Ca 4-20mg/L, Alk.0,2-1mekv/L
# 4 Kalkrik: Ca > 20 mg/L, Alk. > 1 mekv/L

# Oversikt for humus
# Humusinnhold 4 Svært klar: Farge < 10 mg Pt/L, TOC < 2 mg/L
#1 Klar: Farge 10-30 mg Pt/L, TOC 2-5 5 mg/L
#2 Humøs: Farge 30-90 mg Pt/L, TOC 5-15 mg/L
#3 Svært humøs (sjelden): Farge > 90 mg Pt/L, TOC > 15 mg/L

```

# Modell
Vi bruker en modell (GAM eller BRT) for å forklare variasjonen i NEQR ut i fra typologifaktorene som inngår i vanntype (kategoriske variabler) og år (kontinuerlig variabel). Dette muliggjør å predikere nEQR-verdier for kommuner og år med manglende data, basert på sammenhengen mellom observerte nEQR-verdier (responsvariabel) og typologifaktorer/år (forklaringsvariabler). Vi inkluderer kun typologifaktorer representert med minst to ulike koder i datasettet (ForcingData) i modellen. For kyst-habitat er salinitet, bølgeeksponering, miksing, oppholdstid og gjennomstrømming definert av kysttype (+ økoregion for salinitet), og vi bruker derfor kun typologifaktorene kysttype, økoregion og tidevann som forklaringsvariabler i modellen. 

For å kunne inkludere typologifaktorene som faktorer i modellen må vi først:  
1. Fjerne eventuelle observasjoner med manglende verdier for typologifaktorene som skal inngå i modellen, både i ForcingData og PredData   
2. Fjerne eventuelle vannforekomster med typologifaktor-koder som ikke finnes i ForcingData fra PredData (her kan vi ikke predikere fra modellen)   

Vi replikerer så PredData for alle år vi skal predikere for. I utgangspunktet skal vi levere oppdaterte prediksjoner for årene 1990, 2000, 2010, 2011, 2012, 2013, 2014, 2019 og 2024. Men for hver økoregion (og kysttype for kyst-indikatorer) predikerer vi kun for år fra og med første år vi har data for. For eksempel, om vi kun har data fra og med 2010 fra Skagerrak vil vi ikke predikere verdier for kommuner i Skagerrak før 2010.  

```{r prepare_data_for_model, echo = FALSE, eval=TRUE}
# Definerer prediktorvariabler 
# Fjerner eventuelle prediktor-variabler med bare 1 nivå:
num_unique <-
  ForcingData %>%
  summarize_at(variabler, n_distinct, na.rm = TRUE)
print("Antall ulike koder per typologifaktor:")
print(num_unique)
variabler_modell <- c(variabler[num_unique>=2])

if(habitat == "kyst"){
  variabler_modell <- variabler_modell[grepl(paste(c("Oko","Kyst","Tide"), collapse="|"), variabler_modell)]
}

cat("Typologifaktorer som beholdes i modellen:\n", variabler_modell,"\n")

# Bruker datasett uten manglende verdier for variablene til modellen:
ForcingData_modell <-
  ForcingData %>%
  drop_na(all_of(variabler_modell))  

cat("Antall observasjoner i opprinnelig datasett (ForcingData) og etter fjerning av manglende data for typologifaktorer:\n", dim(ForcingData)[1], "\n", dim(ForcingData_modell)[1],"\n")

# Klargjør datasett for prediksjoner
# Bruker prediksjons-datasett uten manglende verdier i de relevante vanntype-variablene: 
PredData_modell <- PredData %>%
  drop_na(all_of(variabler_modell))  

# Fjerner eventuelle faktor-nivå i PredData som ikke finnes i ForcingData:
for (var in variabler_modell){
  PredData_modell <- 
    PredData_modell %>%
    semi_join(ForcingData_modell, by = var)  %>%
      mutate(!!sym(var) := fct_drop(!!sym(var))) # Fjern ubrukte faktor-nivå
}

cat("Antall vannforekomster i PredData før og etter fjerning av vannforekomster med manglende data for typologifaktorer eller typologifaktor-koder som ikke finnes i ForcingData:\n", dim(PredData)[1], "\n", dim(PredData_modell)[1],"\n")

# Lager datasett for prediksjoner per vannforekomst og år:
years <- c(1990, 2000, 2010, 2011, 2012, 2013, 2014, 2019, 2024)
years <- years[years>=min(ForcingData$Year)]
cat("Vi kan totalt sett predikere for følgende år:\n", years,"\n")

PredData_allyrs <-
  PredData_modell %>% 
  slice(rep(row_number(),length(unique(years)))) %>%  # Kopierer for alle år  
  mutate(Year = rep(years, each=dim(PredData_modell)[1]))   # Legger til års-variabel

# For ferskvann: Fjerner kombinasjoner av år og økoregion før år med data tilgjengelig
if(habitat %in% c("innsjo","elver")){
for(x in unique(ForcingData_modell$Okoregion)){
  min_year <- min(ForcingData_modell %>% 
                    filter(Okoregion == x) %>% 
                    dplyr::select(Year))
  PredData_allyrs <- PredData_allyrs %>%
    filter(!(Okoregion == x & Year < min_year)) 
  print(dim(PredData_allyrs)[1])
}
  print_kable(kable(ForcingData_modell %>% group_by(Okoregion) %>% summarise(`Første år` =  min(Year)),
      caption = "Første år med data per økoregion"))
}

# For kyst, år kontinuerlig: Fjerner kombinasjoner av år og økoregion+kysttype før år med data tilgjengelig
if(habitat %in% c("kyst")){
 ForcingData_modell <- ForcingData_modell %>% unite("OkoKyst", Okoregion, Kysttype, remove = FALSE)
 PredData_allyrs <- PredData_allyrs %>% unite("OkoKyst", Okoregion, Kysttype, remove = FALSE)
 
 # Fjerner først kombinasjoner av økoregion og kysttype som ikke finnes i data
 PredData_allyrs <- 
  PredData_allyrs %>%
  filter(OkoKyst %in% ForcingData_modell$OkoKyst)

  # Fjerner så år før vi har data for kombinasjon
  for(x in unique(PredData_allyrs$OkoKyst)){
    min_year <- min(ForcingData_modell %>% 
                      filter(OkoKyst == x) %>% 
                      dplyr::select(Year))
    PredData_allyrs <- PredData_allyrs %>%
      filter(!(OkoKyst == x & Year < min_year)) 
    }

 print_kable(kable(ForcingData_modell %>% group_by(OkoKyst) %>% summarise(`Første år` =  min(Year)),
        caption = "Første år med data per økoregion/kysttype"))
}

```

Vi bruker enten GAM (generalized additive model) eller BRT (boosted regression trees, se <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2656.2008.01390.x" title="A working guide to boosted regression trees">A working guide to boosted regression trees</a>) for å forklare variasjonen i nEQR som funksjon av typologifaktorene og år. I begge tilfeller inkluderer vi år som kontinuerlig variabel (smooth-funksjon i GAM), siden vi antar at det er (potensielt ikke-linjære) trender over tid (ikke tilfeldig år-til-år variasjon). Dette tillater oss å predikere for år vi eventuelt ikke har data for.  

For GAM inkluderer vi interaksjoner mellom år og de kategoriske variablene, hvor den linjære effekten av de kategoriske variablene (stigningstallet) variererer som en "smooth funksjon" av år (definert med "by"-argument i GAM).  

For BRT blir eventuelle interaksjoner det finnes belegg for i datasettet automatisk inkludert, men vi tillater kun 3-dimensjonale interaksjoner (mellom maks. 3 variabler). 

Vi beregner så predikert NEQR per år og vannforekomst ut i fra modellen og informasjon om vanntype per vannforekomst, og kalkulerer deretter gjennomsnitt predikert NEQR per kommune og år. Som nevnt over predikerer vi kun NEQR for kombinasjonen av vannforekomst og år med typologifaktor-koder som inngår i modellen (det finnes data for i ForcingData) og hvor vi har data fra samme økoregion (for ferskvann) eller økoregion OG kysttype (kyst) for samme år eller foregående år.  

Siden BRT er en kombinasjon av statistisk regresjon og maskinlæring er ikke prediksjonene fra BRT assosiert med standardavvik slik som f.eks. en GAM. Vi gjør derfor en bootstrap-prosedyre hvor vi kjører BRTen 100 ganger med 90 % av datasettet og beregner prediksjoner fra denne kjøringer, før vi beregner gjennomsnitt og standardavvik fra disse 100 kjøringene. Dette er strengt tatt unødvendig siden BRT-prosedyren allerede er en iterativ prosess hvor et visst antall (i vårt tilfelle 70%) av datasettet blir brukt i hver iterasjon, og man beregner den beste modellen, og BRT har vist seg å ha bedre prediksjonsevne enn f.eks. GAM. Men boostrap-metoden tillater oss å beregne et standardavvik som vi kan bruke inn i beregningen av lognormalfordeling som trengs for å laste opp data til NI-basen.  

```{r fit_model, echo = FALSE,eval=TRUE}
#mod_type <-"GAM" 
mod_type <-"BRT" 
cat("Type modell: \n", mod_type,"\n")

if(mod_type == "GAM"){
  #require(MuMIn) # For modell-seleksjon med dredge
  require(mgcv) # For GAM

  # Med eller uten interaksjoner mellom år og faktorer?
  interactions <- TRUE;

  # Legg til årsvariabel og eventuelle interaksjoner:
  if (interactions==FALSE) {
    variabler_modell <- c(variabler_modell, paste0("s(","Year",")"));
  } else {
    variabler_modell <- c(variabler_modell, paste0("s(","Year",")"),
                          paste0("s(","Year",", by=",variabler_modell,")"));
  }
  
  # For blåskjell blir det veldig rare prediksjoner når interaksjon mellom år og tidevann er med, fjerner den:
  if (interactions==TRUE & index=="blaaskjell") {
    variabler_modell <- variabler_modell[variabler_modell!="s(Year, by=Tidevann)"]
  }
  
  # Ved å sette family=betar brukes beta-fordeling, som er til data mellom 0 og 1 MEN som eksluderer 0 og 1. Vi har mange 1'verdier, derfor er ikke denne egnet. Har også tested "zero-one-inflated beta regression model" med pakka brms, men denne modellen tar veldig lang tid å kjøre
  xvar <- "Response~" ;
  
  fam <-  "gaussian" ;# Normal fordeling, brukes for NEQR 
  #fam <-  "betar" ;# For fordelinger mellom 0 og 1, men som ekskluderer 0 og 1. 
  if(fam=="betar"){
    ForcingData_modell$Response[ForcingData_modell$Response==1] <- 0.99999;
    ForcingData_modell$Response[ForcingData_modell$Response==0] <- 0.00001
  }
  
  full.model <- gam(formula(paste(xvar, paste(variabler_modell, collapse="+"))),
                      data=ForcingData_modell,na.action = "na.fail",family = fam) ;
  
  # Modellseleksjon kan gjøres basert på AIC. Siden vi er interessert i å forklare mest mulig av variasjoner inkluderer vi alle variabler i den endelige modellen, men antar at eventuelle variabler uten effekt ikke vil påvirke prediksjonene. 
  #aic_tbl <- dredge(full.model);
  #step.model <- get.models(aic_tbl, subset = 1)[[1]]
  step.model <- full.model
  # Sammendrag av modellen:
  print(summary(step.model))
  par(mfrow=c(2,2),mar=rep(2,4))
  gam.check(step.model)
  
  # Predikerer fra modellen og legger til datasettet
  Preds <- predict.gam(step.model, newdata=PredData_allyrs, type = "response", se.fit = TRUE)
  #Preds <- predict(brms_model, newdata=PredData_allyrs)
  
  # Legger til prediksjoner 
  PredData_allyrs <- 
    PredData_allyrs %>% 
    mutate("Prediksjon" = Preds$fit)  %>% 
    mutate("Standardfeil" = Preds$se) 

  # Endrer evt. verdier over 1 eller under 0 for NEQR-prediksjoner:
  if(index != "blaaskjell"){
  PredData_allyrs <- 
    PredData_allyrs %>% 
    mutate(Prediksjon = replace(Prediksjon, Prediksjon > 1, 1))%>%
    mutate(Prediksjon = replace(Prediksjon, Prediksjon < 0, 0.00001))
  }
  
  # Endrer evt. verdier under 0 for blåskjell:
  if(index == "blaaskjell"){
  PredData_allyrs <- 
    PredData_allyrs %>% 
    mutate(Prediksjon = replace(Prediksjon, Prediksjon < 0, 0.00001))
  }
  
  Preds <- Preds$fit
}

if(mod_type == "BRT"){
  require(dismo) 
  require(gbm) 

  variabler_modell <- c(variabler_modell, "Year")
  xvar <- "Response~" 
  explind <- which(names(ForcingData_modell) %in% variabler_modell) # Index predictor variables

  
  # Beregner først optimal kombinasjon av learning rate, tree complexity og bag fraction
  #https://rdrr.io/github/adamlilith/enmSdm/man/trainBrt.html#heading-1
  source("trainBrt_AdamLillith.R")
  set.seed(123)

  mod_tuning <- trainBrt(data = ForcingData_modell,  
                  resp = "Response",             
                  preds = explind,
                  family = "gaussian",
                  learningRate = c(0.001, 0.01, 0.1), #Elith et al. 2008 recommend 0.0001 to 0.1)
                  treeComplexity = c(2, 3, 4),
                  bagFraction=c(0.5, 0.6, 0.7), #Elith et al. 2008 recommend 0.5 to 0.7
                  out=c('tuning', 'model'),
                  verbose=FALSE)

  # Trekk ut beste kombinasjon 
  selected <- mod_tuning$tuning[1,c(2:4,7)]
  print("Beste kombinasjon av parametere for BRT:")
  print(selected)

  # Kjører BRT. For å få et mål på variasjon gjøres dette X ganger (bootstrap) på 90% av datasettet, og vi beregner snitt og standardavvik fra prediksjonene per modell
  X <- 100
  pred_mat <- matrix(NA,nrow=dim(PredData_allyrs)[1],ncol=X)
  for(x in 1:X){
  ForcingData_modell_x <- ForcingData_modell %>% 
    sample_frac(0.9)
    
  full.model <- gbm.step(data = ForcingData_modell_x,
                            gbm.x = explind,
                            gbm.y = "Response",
                            learning.rate = selected[1], # how slow the model is learning
                            tree.complexity = selected[2], # number of splits (possible interactions between variables)
                            family = "gaussian", # gaussian=normal, bernoulli=binomial, poisson=counts
                            bag.fraction = selected[3], # proportion of observations used each iteration)
                            #      n.trees = 100,
                            plot.main = FALSE,
                            silent = TRUE)
  # tot.dev <- full.model$self.statistics$mean.null # mean null deviance
  # res.devCV <- full.model$cv.statistics$deviance.mean  # mean residual deviance cv
  # dev.expCV <- round((tot.dev-res.devCV)/tot.dev,2) # deviance explained
  # CorCV <- round(full.model$cv.statistics$correlation.mean,2)
  # print(paste0("Deviance explained, cross validated: ",dev.expCV))
  # print(paste0("Correlation, cross validated: ",CorCV))
  
  # Predikerer fra modellen
  pred_mat[,x] <- predict.gbm(full.model, newdata=PredData_allyrs, type = "response")
  rm(ForcingData_modell_x)
  }
  # Legger til prediksjoner 
  PredData_allyrs <- 
    PredData_allyrs %>% 
    mutate("Prediksjon" = apply(pred_mat,1,mean))  %>% 
    mutate("Standardfeil" = apply(pred_mat,1,sd)) 

  # Endrer evt. verdier over 1 eller under 0 for NEQR-prediksjoner:
  if(index != "blaaskjell"){
  PredData_allyrs <- 
    PredData_allyrs %>% 
    mutate(Prediksjon = replace(Prediksjon, Prediksjon > 1, 1))%>%
    mutate(Prediksjon = replace(Prediksjon, Prediksjon < 0, 0.00001))
  }
  Preds <- apply(pred_mat,1,mean)
  
  }

# Har også testa en "brm" (Bayesian Generalized (Non-)Linear Multivariate Multilevel Models) som kan inkludere zero-one-inflated beta distribution, noe som passer perfekt i vårt tilfelle. Men disse modellene er veldig tunge å kjøre og predikere fra, så det er ikke praktisk å bruke i dette tilfellet med mange variabler
#xvar_zero <- "zoi~"
# brms_model <- brm(
#   bf(paste(xvar, paste(variabler_modell, collapse="+"))),
#               # formula(paste(xvar_zero, paste(variabler_modell, collapse="+")))),
#   data = ForcingData_modell,
#   family = zero_one_inflated_beta())

#summary(full.model)
#summary(brms_model)
#plot(brms_model)
```

I noen tilfeller, spesielt med GAM, får vi prediksjoner over 1, som vi setter til 1. 
```{r predictions,eval=TRUE, echo=FALSE}
par(mfrow=c(2,1),mar=rep(2,4))
hist(Preds,main="Originale prediksjoner",xlab="",ylab="")
hist(PredData_allyrs$Prediksjon,main="Nye prediksjoner",xlab="",ylab="")

# Beregner gjennomsnitts prediksjon og standardavvik per kommune og år. Tar gjennomsnitt av standardavvik i stedet for standardavvik av standardavvik fordi vi ønsker å forstå den typiske variasjonen i prediksjonene, ikke variasjonen av variasjonen. Standardavviket av standardavviket blir mindre enn gjennomsnittet av standardavviket
PredData_means <- 
  PredData_allyrs %>% 
   filter(!is.na(Kommunenr)) %>%
  group_by(Kommunenr,Year) %>% 
  summarise(Prediksjon_snitt = mean(Prediksjon),
            Standardfeil_snitt = mean(Standardfeil)) %>% 
  ungroup(Kommunenr) 

write.table(PredData_means,paste0("../../02_Predictions/",index,".csv"),quote = FALSE, sep = ",", row.names = FALSE)

rm(Preds, step.model)
```

# Sammenligning mellom observasjonsdata og prediksjoner
Kartet under viser gjennomsnittilig NEQR per kommune, basert på innsamlede data per år i det tilgjengelige datagrunnlaget. 
```{r maps, echo=FALSE, message=FALSE,eval=TRUE, fig.cap = "Gjennomsnitt NEQR-verdi per år og kommune."}
col_scale <- brewer.pal(11, 'Spectral')
# Leser inn shapefil:
shapefile <- "../../01_Data/04_GIS/01_Kommuner/Norway_utm33n.shp"
shp<- st_read(shapefile, quiet = TRUE) %>%
  rename(Kommunenr=KOMM)

# For blåskjell, replikerer observasjoner som strekker over flere kommuner
if(index == "blaaskjell"){
ForcingData_modell <- 
  ForcingData_modell %>%
  mutate(Komm5 = as.numeric(Komm5)) #Setter kommunenr til numerisk

ForcingData_modell <- pivot_longer(ForcingData_modell,
                     cols = paste0("Komm",1:7),   # Kopierer for alle kommuner  
                     values_to = "Kommunenr")

ForcingData_modell <- 
  ForcingData_modell %>%
  filter(!is.na(Kommunenr))
}


ylims <- c(0,1)

xvar <- "Response_mean"

years <- sort(unique(ForcingData_modell$Year))
# Fram til 2010 plotter vi gjennomsnitt per 10-års periode
years <- years[years>=1980]
years[years<2010] <- floor(years[years<2010]/10)*10
years <- unique(years)

maps <- list()

for(y in 1:length(years)){
  # Trekker ut prediksjoner for gitt år eller periode (før 2010), tar gjennomsnitt per kommune:
  if(years[y]<2010){
    years_y <-seq(years[y],years[y]+9,by=1) 
  } else {
    years_y <-years[y] 
  }

  ForcingData_modell_y <- ForcingData_modell  %>%
    filter(Year %in% years_y) %>%
    group_by(Kommunenr) %>%
    summarise(Response_mean = mean(Response)) %>%
    dplyr::select(Kommunenr, all_of(xvar))

  # Slår sammen shapefil og prediksjoner:
  shp_y <- shp %>%
    left_join(ForcingData_modell_y)
  
  rm(ForcingData_modell_y)

  # Definerer plot for gitt år:
  maps[[y]] <-  ggplot(data = shp_y ) +
    geom_sf(aes(fill = get(xvar)), colour = "dark grey", size = 0.1)  +
    scale_fill_gradientn(name=xvar,colours = col_scale, na.value = "white") + # Fargeskala
        expand_limits(fill=ylims) +  #Grenser for skala
  theme_void() +
  ggtitle(years_y) + # Tittel
  theme(legend.position = "none", plot.margin = unit(rep(.01, 4), "lines")) # Fjern skala fra plot
  
   if(years[y]<2010){
    maps[[y]] <- maps[[y]] + ggtitle(paste0(min(years_y),"-",max(years_y)))
  } 
}

#Plot for legend:
# legend <- ggplot(data = shp_y ) +
#     geom_sf(aes(fill = get(xvar)), colour = "dark grey", size = 0.1)  +
#     scale_fill_gradientn(name=xvar,colours = col_scale, na.value = "white") + # Fargeskala
#         expand_limits(fill=ylims)  +
#   theme(legend.justification = "left", legend.title = element_blank())
# 
# maps[[y+1]] <- cowplot::get_legend(legend)

grid.arrange(grobs = maps, ncol=6)

```

Kartet under viser gjennomsnittilig predikert NEQR per kommune, basert på den statistiske modellen, for de årene som Naturindeksen skal leveres. Som beskrevet over beregnes prediksjonene kun for en gitt økoregion om vi har data fra den økoregionen (og kysttypen for marine indikatoren) for samme år eller foregående år. 

```{r plot_maps_model,eval=TRUE, echo=FALSE, fig.cap = "Predikert NEQR-verdi per år og kommune"}
# Plot for prediksjoner per år og kommunenr
years <- sort(unique(PredData_means$Year))

xvar <- "Prediksjon_snitt"
#xvar <- "Standardfeil_snitt"

maps <- list()

for(y in 1:length(years)){
  # Trekker ut prediksjoner for gitt år
  PredData_means_y <- PredData_means  %>% 
    filter(Year == years[y]) %>%
    dplyr::select(Kommunenr, all_of(xvar))
  
  # Slår sammen shapefil og prediksjoner 
  shp_y <- shp %>%
      left_join(PredData_means_y)
  
  rm(PredData_means_y)
 
  # Definerer plot for gitt år
  maps[[y]] <- ggplot(data = shp_y ) +
    geom_sf(aes(fill = get(xvar)), colour = "dark grey", size = 0.1)  +
    scale_fill_gradientn(name=xvar,colours = col_scale, na.value = "white") + # Fargeskala
        expand_limits(fill=ylims) +  #Grenser for skala
  theme_void() +
  ggtitle(years[y]) + # Tittel
  theme(legend.position = "none") # Fjern skala fra plot
}

#Plot for legend:
legend <- ggplot(data = shp_y ) +
    geom_sf(aes(fill = get(xvar)), colour = "dark grey", size = 0.1)  +
    scale_fill_gradientn(name=xvar,colours = col_scale, na.value = "white") + # Fargeskala
        expand_limits(fill=ylims)  +
  theme(legend.justification = "left", legend.title = element_blank())
  
maps[[y+1]] <- cowplot::get_legend(legend)

grid.arrange(grobs = maps, ncol=4)
#g<-arrangeGrob(grobs = maps, ncol=4)
#ggsave(file="Plots_allyears/AIP_pred_new.pdf", g)
```

Plottet under viser predikert NEQR per kommune sammenlignet med datagrunnlaget (gjennomsnittlig målt NEQR per kommune), for de kommunene hvor vi har data for samme år som prediksjonene gjøres. Korrelasjonskoeffisient og p-verdi for korrelasjonen er vist med rød skrift i plottet, og den linjære sammenhengen er vist som svart linje. 

```{r plot_corrs_dat_model,eval=TRUE, echo=FALSE, fig.cap = "Korrelasjon mellom data og prediksjoner på kommunenivå."}
ForcingData_modell_per_y <- ForcingData_modell  %>%
    group_by(Kommunenr, Year) %>%
    summarise(Response_mean = mean(Response))

corrdat <- PredData_means  %>% 
  left_join(ForcingData_modell_per_y) %>% 
  filter(!is.na(Response_mean))

r <- round(cor(corrdat$Response_mean, corrdat$Prediksjon_snitt), 2)
p <- cor.test(corrdat$Response_mean, corrdat$Prediksjon_snitt)$p.value

ggplot(corrdat, aes(Response_mean, Prediksjon_snitt)) +
  geom_point()  + 
  geom_smooth(method="lm", col="black") + 
  annotate("text", x=0.02, y=0.99, label=paste0("r = ", r), col="red") +
  annotate("text", x=0.02, y=0.965, label=paste0("p = ", round(p, 3)), col="red") +
  theme_classic() + ylab("Prediksjon (snitt per kommune)") + xlab("Observert (snitt per kommune)")

```

# Gjennomsnittlige verdier per økoregion

```{r plot_means, eval=TRUE, echo=FALSE, fig.cap = "Gjennomsnitts-prediksjoner per år og økoregion (for ferskvann dekker kategorien Nord-Norge ytre hele Nord-Norge)"}
# Plot for prediksjoner per år og kommunenr

PredData_means_regions <- 
  PredData_means %>% 
  left_join(PredData_modell %>% dplyr::select(Kommunenr, Økoregion)) %>% 
  group_by(Økoregion,Year) %>% 
  summarise(Mean = mean(Prediksjon_snitt),
            Sd = sd(Prediksjon_snitt))

regions <- unique(PredData_means_regions$Økoregion)
years <- unique(PredData_means_regions$Year)

plots <- list()

for(i in 1:length(regions)){
  # Trekker ut snitt for gitt region
  dat_i <- PredData_means_regions %>% 
    filter(Økoregion == regions[i]) 
  
  # Definerer plot for gitt region
  plots[[i]] <- ggplot(dat_i, aes(x = Year, y = Mean)) + 
            geom_linerange(aes(x = Year, ymin = Mean-Sd, ymax = Mean+Sd), dat_i) +
            geom_point(shape = 21, bg = "cyan", size = 3) +
            theme_bw() +
            ggtitle(regions[i]) +
            xlim(range(years)) +
            ylim(c(0,1))

}

grid.arrange(grobs = plots, ncol = ceiling(length(regions)/2))

```

# Opplasting til NI-databasen
Predikerte NEQR-verdier blir lasta opp til NI-databasen på nett ved å bruke NIcalc-biblioteket i R i scriptet <a href="C:/Users/KVI/NIVA/240176 - Naturindeks for Norge 2025 - Documents/03_Data_and_analyses/naturindeks/analyser/NICalc_upload.r" download>NICalc_upload.r</a>. Laster først ned den eksisterende databasen for den gitte indikatoren, og oppdaterer så verdi (=prediksjon) og 'distrObjects' (beregnes av funksjoner i NIcalc). Verdier for kommuner og år vi ikke har prediksjoner for, men som finnes i databasen allerede, blir satt til NA.

